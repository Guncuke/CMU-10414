# Homework 3


## Lecture11

矩阵乘法如何加速：
1. 分块计算（一次计算出一块的结果）
2. 每次一行（列）的数据会被重复计算N次，可以放入L1 cache，减少访问时间。

## Q.1 (Python后端)
`Reshape`只需修改`shape`的形状，然后根据形状重新计算`stride`，然后重新排布。
`Permute`需要根据排序后新的`shape`和`stride`，重新排布。
`broad_cast`将维度为1的部分`stride`设置为0。
`__getitem__`比较复杂，需要根据每一个维度的起点，首先计算出偏移量，然后根据每一个维度的起点，终点和步长计算出`shape`，并且将每一个维度的步长乘以`step`。


## Q.2 (CPU后端)
`Compact`将a的内容，通过`shape`,`offset`,`stride`取出对应的位置，然后按+1的顺序放入`out`中。

`EwiseSetitem`将`a`的内容按顺序取出，放入`out`的对应位置，`out`非`compact`，需要根据`stride` `offset`计算对应放入的位置。

`ScalarSetitem`同理，赋值变为常数。

## Q.3
已经假设`a`和`b`都是`compact`的，直接遍历一遍即可。

## Q.4
归约操作，`out`的维度是`a`/`reduce_size`，注意映射关系。

## Q.5
矩阵乘，首先是最简单的三层循环。然后是使用4D矩阵的乘法。
一开始也疑惑，后来才明白4D矩阵底层存储方式就是按照4D矩阵的存储方式来存储的，所以一个TILE的内存位置也是连续的。因此只需要找到按照TILE划分块后，`a`和`b`对应的起始下标即可。

## Q.6(CUDA后端)
`Compact`:需要从一个`gid`，找到`a`对应的`stride`和`offset`下的位置。那么就是要计算，`a`数据中的第`gid`个元素，在内存中的哪个位置。那么我们就需要先还原成多维数据，然后再根据每一维度的`stride`*`shape`找到在`a`中的位置。

## Q.7
剩下的操作都和CPU版本同理，改写成CUDA版本，每个GID代表一个线程，处理一个位置的计算。

## Q.8
规约操作，这里的做法是使用out->size个线程来计算，每个线程需要计算`recude_size`次规约操作。

## Q.9
这里只实现了最基本的操作，开M*P个线程，每个线程计算结果矩阵中一个位置，优化的话后面再写。（share_memory，TILE...）
